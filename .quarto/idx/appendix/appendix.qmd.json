{"title":"Technical Appendix","markdown":{"yaml":{"title":"Technical Appendix","format":"html"},"headingText":"Load packages","containsRefs":false,"markdown":"\n\n```{r}\n#| echo: False\nlibrary(tidycensus)\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(scales)\nlibrary(RColorBrewer)\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(tigris)\nlibrary(patchwork)\nlibrary(here)\n\noptions(tigris_use_cache = TRUE, tigris_progress = FALSE) \n```\n\n# PHASE 1: DATA PREPARATION\n\n## 1.1 Load and Philadelphia house sales data\n```{r}\n# Load Philly Property Sales data\nphl_sales <- read_csv(\"../data/raw/opa_properties_public.csv\", show_col_types = FALSE)\n```\n\n### Filter to residential properties, 2023-2024 sales\n```{r}\n# Check data types\n# glimpse(phl_sales)\n\nphl_sales_res_23_24 <- phl_sales |>\n  filter(\n    category_code == 1, # Residential\n    year(sale_date) %in% c(2023, 2024), # 2023-24 sales\n    !is.na(category_code) & !is.na(sale_date) # Handle nulls\n  )\n```\n\n### Remove obvious errors\n```{r}\nphl_sales_clean <- phl_sales_res_23_24 |>\n  filter(\n    # Some sale_price are unrealistically too low ($0, $1 etc.)\n    sale_price >= 10000,\n    # Exclude homes with 0 bathrooms\n    number_of_bathrooms > 0,\n    # Some areas are unrealistically low (0, 1, etc.)\n    total_area > 1,\n    # Some 0's remain in total_liveable_area after first area filter\n    total_livable_area > 0,\n    # Filter our unrealistic year built\n    year_built >= 1750\n    ) \n```\n\n### Handle missing values\n\n```{r}\n# Check how many features have NA values\n# sum(is.na(phl_sales_clean$number_of_bedrooms))\n# sum(is.na(phl_sales_clean$number_of_bathrooms))\n# sum(is.na(phl_sales_clean$total_livable_area))\n# sum(is.na(phl_sales_clean$year_built))\n\n# Remove the 2 observations with NA values for number of bedrooms\nphl_sales_clean <- phl_sales_clean |>\n  filter(\n    !is.na(number_of_bedrooms)\n  )\n```\n\n### Preliminary Feature Engineering: Age = sale date - year built\n```{r}\nphl_sales_clean <- phl_sales_clean |>\n  mutate(\n    sale_year = year(sale_date),\n    age = sale_year - year_built\n  )\n```\n\n### Document all cleaning decisions\n\n\n- Our methodology for cleaning the Philadelphia home sales data is to focus on the features used in our model. As a group, we decided on the following independent variables to consider in our data exploration and model building to be: number of bathrooms, number of bedrooms, total livable area, and year built. We recognize that there is some risk of collinearity between these structural features, which will later be monitored and addressed if needed in the model building stage. Additionally, we also had to clean the sales price column since this is the variable we aim to predict in our model.\n\n\n- Filter for only **residential properties** & **sales made in 2023-24** (per instructions).\n\n\n- Filter for **realistic sales price** >= $10,000.\n\n\n- Filter for houses with **at least 1 bathroom**. We will keep observations where **number of bedrooms = 0** as this likely signifies a studio apartment. However, it is not feasible for homes to have zero bathrooms, so we will enforce a constraint that a home must have at least 1 bathroom to preserve data integrity.\n\n\n- Filter for **realistic total area** > 1 sq ft & **realistic total livable area** > 0 sq ft.\n\n\n- Filter for **year built** >= 1750 (some homes were built in year 0).\n\n\n- **Handle missing values:** We removed any missing values in our dependent variable of sales price, since it is crucial we have a true and accurate measure for prediction. We also checked which of our predictor variables had NA values after filtering. Only number of bedrooms had 2 remaining NA values. The rest had no NA values. To remedy this, we will remove the 2 observations from our data. Note, if there was substantial missing values in our predictors, we could use strategies such as imputing the NA values with the mean or median to use when building our model. \n\n\n- **Preliminary feature engineering:** Rather than using year built in our Automated Valuation Model, it makes more sense to create a new variable **age** that is equal to the sale date minus the year built. The **age** variable is often easier to interpret in exploratory plots with the newer houses appearing on the left and older ones on the right. This is primarily a stylistic preference: the overall pattern of the data will remain the same but mirrored.\n\n\n## 1.2 Load Secondary Data\n\n### Census\n\nPurpose: Pull demographic and housing data at the block group level for Philadelphia from the 2023 5-year ACS. This data will provide predictors for neighborhood characteristics in our modeling.\n\nVariables Collected:\n\nMedian household income (B19013)\n\nPercentage of family households (B11001)\n\nEducation attainment: percent of population 25+ with a bachelor’s degree or higher (B15003)\n\nHousing vacancy rate (B25002)\n\nRacial composition: percent white (B02001)\n\n```{r api key,eval=FALSE, include=FALSE}\n\n# This Block is the code that I used to Pull and Manipulate the Census Data. I condensed it and included it in one block for the team's reference. This output files have been uploaded to the project and will be pulled in the next code block to reduce computation.\n\ncensus_api_key <- (\"8deb926015351433bef092c55a5e8a90573283bd\")\n\n\n#philly-tract-data\n\n# Define parameters\nmy_state  <- \"Pennsylvania\"\nmy_county <- \"Philadelphia\"\nacs_year  <- 2023  # latest available 5-year ACS (2019–2023)\n\n# Median Household income\nincome <- get_acs(\n  geography = \"block group\",\n  state = my_state,\n  county = my_county,\n  table = \"B19013\",\n  year = acs_year,\n  survey = \"acs5\"\n) %>%\n  select(GEOID, median_income = estimate)\n\n# Percentage of family households\nhouseholds <- get_acs(\n  geography = \"block group\",\n  state = my_state,\n  county = my_county,\n  table = \"B11001\",\n  year = acs_year,\n  survey = \"acs5\"\n) %>%\n  select(GEOID, variable, estimate) %>%\n  tidyr::pivot_wider(names_from = variable, values_from = estimate) %>%\n  mutate(\n    family_hh = B11001_002,\n    total_hh  = B11001_001\n  ) %>%\n  select(GEOID, family_hh, total_hh)\n\n# Education (percent bachelor’s or higher)\neducation <- get_acs(\n  geography = \"block group\",\n  state = my_state,\n  county = my_county,\n  table = \"B15003\",\n  year = acs_year,\n  survey = \"acs5\") %>%\n  select(GEOID, variable, estimate) %>%\n  tidyr::pivot_wider(names_from = variable, values_from = estimate) %>%\n  mutate(\n    total_25plus = B15003_001,\n    bachelors_plus = B15003_022 + B15003_023 + B15003_024 + B15003_025,\n    pct_bachelors = 100 * bachelors_plus / total_25plus\n  ) %>%\n  select(GEOID, pct_bachelors)\n\n# Percent of vacant homes = number vacant/total homes\nvacancy <- get_acs(\n  geography = \"block group\",\n  state = my_state,\n  county = my_county,\n  table = \"B25002\",\n  year = acs_year,\n  survey = \"acs5\"\n) %>%\n  select(GEOID, variable, estimate) %>%\n  tidyr::pivot_wider(names_from = variable, values_from = estimate) %>%\n  mutate(\n    total_units = B25002_001,\n    vacant_units = B25002_003,\n    pct_vacant = 100 * vacant_units / total_units\n  ) %>%\n  select(GEOID, pct_vacant)\n\n# retrieving percent white for block group\ndemographics <- get_acs(\n  geography = \"block group\",\n  state = my_state,\n  county = my_county,\n  table = \"B02001\",\n  year = acs_year,\n  survey = \"acs5\") %>%\n  select(GEOID, variable, estimate) %>%\n  tidyr::pivot_wider(names_from = variable, values_from = estimate) %>%\n  mutate(\n    total_pop = B02001_001,\n    white_pop = B02001_002,\n    pct_white = 100 * white_pop / total_pop\n  ) %>%\n  select(GEOID, pct_white)\n\nphilly_blockgroup <- income %>%\n  left_join(households, by = \"GEOID\") %>%\n  left_join(education, by = \"GEOID\") %>%\n  left_join(vacancy, by = \"GEOID\") %>%\n  left_join(demographics, by = \"GEOID\")\n\nhead(philly_blockgroup)\n\n#Block Group Geometry Pull\nphilly_bg_sf <- get_acs(\n  geography = \"block group\",\n  state = \"PA\",\n  county = \"Philadelphia\",\n  table = \"B19013\",\n  year = 2023,\n  survey = \"acs5\",\n  geometry = TRUE)\n\nhead(philly_bg_sf)\n\n# Geometry - Cenus Data Merge\nphilly_bg_map <- philly_bg_sf %>%\n  left_join(philly_blockgroup, by = \"GEOID\")\n```\n\n#### Load Philly Census Data from Previously Retrieved Files\n\n```{r}\n# Relative to project root\ncensus_path <- here(\"data\", \"Philly Census\")\n\ncensus_csv_path <- file.path(census_path, \"philly_blockgroups_metrics.csv\")\ncensus_shp_path <- file.path(census_path, \"philly_blockgroups.shp\")\n\n# Csv with Block Group Geo IDs and metrics\nphilly_blockgroup <- read_csv(census_csv_path, show_col_types = FALSE)\n\n# Shp File including geometry\nphilly_bg_sf <- st_read(census_shp_path, quiet = TRUE)\n```\n\n#### Observe Summary Statistics from target metrics.\n\n```{r}\nnumeric_vars <- c(\"median_income\", \"pct_white\", \"pct_bachelors\", \"pct_vacant\")\nphilly_blockgroup %>%\n  select(all_of(numeric_vars)) %>%\n  summary()\n```\nA quick check of the census variables reveals some missing values and lower than epected values in median income. We will note this information but retain the missing values for now to maintain the full pitcure of census blocks.\n\n\n### Cleaning Methodology (Census)\n\nMedian income: Selected only the estimate column and renamed it for clarity.\n\nHousehold composition: Pivoted ACS table to wide format, then calculated total households and family households.\n\nEducation: Pivoted to wide format, summed relevant categories to compute percent of population with a bachelor’s degree or higher.\n\nVacancy: Pivoted to wide format, calculated percent of homes vacant (vacant_units / total_units * 100).\n\nRacial composition: Pivoted to wide format, computed percent white.\n\nMerging: Combined all datasets by GEOID to create a single dataframe philly_blockgroup with all variables.\n\nGeometry: Pulled block group shapefiles with ACS geometry and merged with philly_blockgroup to create philly_bg_map.\n\n### Neighborhood (Polygon)\n\nReading in Philadelphia Neighborhoods as a shp object. This will allow us to aggregate data on neighborhoods to identify catagorical metrics.\n\n```{r}\nneighborhood_folder <- here(\"data\", \"philadelphia-neighborhoods\")\nneighborhood_path   <- file.path(neighborhood_folder, \"philadelphia-neighborhoods.shp\")\n\n# Read the shapefile\nphilly_neighborhoods <- st_read(neighborhood_path, quiet = TRUE)\n\nhead(philly_neighborhoods)\n```\n\n\n### City Centers (Amenities)\n\n```{r}\n\n```\n\n### Education\n\nWe used two datasets from OpenDataPhilly.com to identify schools geolocation and populated the metrics off Attendance percent and Withdrawal volumes from those schools.\n\n```{r}\n# Relative to project root\neducation_path <- here(\"data\", \"Education\")\n\neducation_csv_path <- file.path(education_path, \"philadelphia_schools.csv\")\neducation_shp_path <- file.path(education_path, \"Schools Shape\", \"Schools.shp\")\n\n# Csv with School Names and metrics\nphilly_schools <- read_csv(education_csv_path, show_col_types = FALSE)\n\n# Shp File including geometry\nphilly_schools_sf <- st_read(education_shp_path, quiet = TRUE)\n```\n\nWe joined the csv file containing the metrics with the shp file containing geoloaction.\n\n```{r}\n# Joining Schools csv metrics to shp file. Joined on 'location_i' (shp) and 'School_code (csv)\n# Keeping metrics for Attendance and Withdrawals\n\n# Select relevant metrics from CSV\nschool_metrics <- philly_schools %>%\n  select(School_code, Attendance, Withdrawals) %>%\n  mutate(School_code = as.character(School_code))\n\nphilly_schools_sf <- philly_schools_sf %>%\n  left_join(school_metrics,\n            by = c(\"location_i\" = \"School_code\"))\n```\n```{r}\nphilly_schools_sf_clean <- philly_schools_sf %>%\n  filter(!is.na(Attendance) & !is.na(Withdrawals))\n```\n```{r}\nnames(philly_schools_sf_clean)\nnrow(philly_schools_sf_clean)\n```\nOnce joined, we dropped rows that did not have values in Attendance and Withdrawal. This resulted in 204 public schools and their metrics located in Philadelphia City Limits.\n\n### Joining data together\n\n```{r}\n\n```\n\n\n# PHASE 2: EXPLORATORY DATA ANALYSIS\n\n### Distribution of sale prices (histogram)\n\n```{r}\n# Calculate the median / mean to plot\nprice_median <- median(phl_sales_clean$sale_price, na.rm = TRUE)\n\nggplot(phl_sales_clean, aes(sale_price)) +\n  geom_histogram(bins = 60, fill = \"darkseagreen3\", color = \"black\") +\n  geom_vline(xintercept = price_median, linetype = 5) +\n  annotate(\"text\",\n           x = price_median, \n           y = 6300, \n           label = \"Median\",\n           hjust = -0.2, \n           color = \"black\", \n           size = 3) +\n  scale_x_continuous(labels = label_dollar()) +\n  labs(title = \"Distribution of Home Sale Prices\",\n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Sale Price\",\n       y = \"Count\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n**Interpretation:** The histogram plot above shows the full distribution of home sale prices for residential properties in 2023-2024 from our cleaned dataset. The data is extremely right-skewed, highlighting a majority of prices under \\$500,000 with a long tail of more expensive homes thereafter. The main issue with the extreme outliers of home prices exceeding \\$5 million that make the visibility of this plot hard to interpret. Also, there are major gaps at higher sales prices as we see the data become more spread out, further indicating the presence of outliers. Therefore, to remedy this, we will plot a second histogram of the price distribution, excluding the top 5% of sales prices from the original cleaned dataset.\n\n```{r}\n# Create new df, filtering out the top 5% of house prices (outliers)\nprice_95_perc <- quantile(phl_sales_clean$sale_price, 0.95, na.rm = TRUE)\ndf_95_exclude <- filter(phl_sales_clean, sale_price <= price_95_perc)\n\n# Calculate the median / mean to plot from trimmed distribution\nprice_median_95_exc <- median(df_95_exclude$sale_price, na.rm = TRUE)\nprice_mean_95_exc <- mean(df_95_exclude$sale_price, na.rm = TRUE)\n\nggplot(df_95_exclude, aes(sale_price)) +\n  geom_histogram(bins = 20, fill = \"darkseagreen3\", color = \"black\") +\n  geom_vline(xintercept = price_mean_95_exc, linetype = 5) +\n  geom_vline(xintercept = price_median_95_exc, linetype = 5) +\n  annotate(\"text\",\n           x = price_mean_95_exc,\n           y = 2400,\n           label = \"Mean\", \n           hjust = - 0.1, \n           color = \"black\", \n           size = 3) +\n  annotate(\"text\",\n           x = price_median_95_exc, \n           y = 2450, \n           label = \"Median\",\n           hjust = 1.25, \n           color = \"black\", \n           size = 3) +\n  scale_x_continuous(labels = label_dollar()) +\n  labs(\n    title = \"Distribution of Home Sale Prices\",\n    subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n    caption = \"Histogram and median/mean statistics were computed on filtered sample (sale price ≤ 95th percentile) for better visibility.\",\n    x = \"Sale Price\",\n    y = \"Count\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  ) \n```\n\n**Interpretation:** In this revised histogram, we get a much better sense of how the sales prices are distributed without the presence of extreme outliers. As we saw before, the data is definitely right-skewed since the median (\\$235,250) is less than the mean (\\$322,231) even when removing large outliers from the top 5% of the distribution. We can visualize that the standard housing market in Philadelphia from 2023-2024 ranges between \\$0 and \\$800,000. The distribution has a single peak around \\$200,000, indicating that it is unimodal with a typical (or most common) home sale price in the realm of \\$150,000 to \\$250,000. This is an indication that it may be best to omit these significant outliers from our dataset when building our model for home sale price prediction. The homes on the higher end of the sale price distribution are determined by a combination of structural features (such total livable area) and spatial features (such as nearby city centers) that drive up the prices of these homes. The goal of this study is to determine what features, both structural and spatial, are significant in predicting home sale prices in Philadelphia and create an accurate model to help policy makers in valuating property tax assessments.\n\n### Geographic distribution (map)\n\n```{r}\n\n```\n\n**Interpretation:**\n\n### Price vs. structural features\n\n#### 1. Number of Bathrooms\n\n```{r}\nggplot(phl_sales_clean, aes(x = factor(number_of_bathrooms), y = sale_price)) +\n  geom_boxplot(fill = \"lightcyan2\", outlier.color = \"firebrick\", outlier.alpha = 0.2) +\n  scale_y_continuous(labels = scales::label_dollar()) +\n  labs(title = \"Distribution of Home Sale Prices by Number of Bathrooms\", \n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Bathrooms\", \n       y = \"Sale Price\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n**Interpretation:** Since number of bathrooms is a discrete variable, a scatter plot is not suitable to visualize this predictor's relationship with the target variable of sale price; therefore, we opted to use box plots instead. In this first plot, we see a distinct positive relationship between number of bathrooms and home sale price. Intuitively, this makes sense since homes with more bathrooms should on average sell at higher prices. Another trend is that there are more outliers in homes with less bathrooms (between 1 and 3). These outliers are likely due to external spatial factors such as neighborhoods. Housing prices tend to surge in highly desirable neighborhoods such as Rittenhouse Square, which explains the presence of many outliers plotted above the upper bound of these boxplots. Another trend is that variance of sale prices begins to significantly widen for homes with more than 3 bedrooms. This suggests that larger homes with more bathrooms experience more price dispersion relative to those with less bathrooms. Lastly, it is worth noting that there are very few observations of homes with 8 or 12 bathrooms, indicating that it would be beneficial to remove them from our dataset to better capture the true relationship between price and number of bathrooms.\n\n```{r}\nggplot(phl_sales_clean, aes(x = factor(number_of_bathrooms), y = log(sale_price))) +\n  geom_boxplot(fill = \"lightcyan2\", outlier.color = \"firebrick\", outlier.alpha = 0.2) +\n  scale_y_continuous(labels = scales::label_dollar()) +\n  labs(title = \"Distribution of Log(Home Sale Prices) by Number of Bathrooms\", \n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Bathrooms\", \n       y = \"Log(Sale Price)\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n**Interpretation:** In addition, we also plotted with the y-axis transformed to the log of sales price. We notice that there is still a positive relationship that appears more linear than the first plot. The log transformation helps reduce the effect of extreme outliers by compressing the distribution of house sale prices. This transformation also serves to center the distributions as noted by the presence of both positive and negative outliers. These benefits suggest that log-transforming our target variable for a linear regression is the best suitable method to yield an accurate model. \n\n#### 2. Number of Bedrooms\n\n```{r}\nggplot(phl_sales_clean, aes(x = factor(number_of_bedrooms), y = sale_price)) +\n  geom_boxplot(fill = \"lightcyan2\", outlier.color = \"firebrick\", outlier.alpha = 0.2) +\n  scale_y_continuous(labels = scales::label_dollar()) +\n  labs(title = \"Distribution of Home Sale Prices by Number of Bedrooms\", \n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Bedrooms\", \n       y = \"Sale Price\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n**Interpretation:** The above plot to measure the relationship between home sale price and number of bedrooms is positive, indicating that homes with more bedrooms tend to sell at higher prices. However, this relationship looks significantly less strong than the relationship between sale price and number of bathrooms. We observe many outliers across homes with various bedroom sizes, most notably those with 2 - 5 bedrooms. The intuition is that these size households are more likely to be sold on the market with higher variability in sales prices, particularly in the upper tail, demonstrating right-skew. These high outliers represent luxury properties that sell for abnormally high sale prices due to other external variables like neighborhood, size etc. Again, we have a small number of very large homes with 10, 11, and 12 bedrooms that are candidates for removal before building our model.\n\n```{r}\nggplot(phl_sales_clean, aes(x = factor(number_of_bedrooms), y = log(sale_price))) +\n  geom_boxplot(fill = \"lightcyan2\", outlier.color = \"firebrick\", outlier.alpha = 0.2) +\n  scale_y_continuous(labels = scales::label_dollar()) +\n  labs(title = \"Distribution of Log(Home Sale Prices) by Number of Bedrooms\", \n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Bedrooms\", \n       y = \"Log(Sale Price)\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n**Interpretation:** As before, we can log-transform the target variable log(sale price) to better visualize the relationship with number of bedrooms. We still see a positive relationship that appears more linear than in our earlier plot. As before, the log-transformation stabilizes the variance to mitigate outliers and centers the data demonstrated by outliers at both the upper and lower tails. The strength of the relationship still appears to be not as obvious as with the number of bathrooms. In other words, number of bathrooms may be a more suitable predictor of sale price from these EDA observations. To avoid the risk of multicollinearity, we will keep this finding in mind when determining what structural features should be included in our final model.\n\n#### 3. Total Livable Area\n\n```{r}\nggplot(phl_sales_clean, aes(x = total_livable_area, sale_price)) +\n  geom_point(alpha = 0.1, size = 1) +\n  geom_smooth(method = \"lm\", se = FALSE, linetype = 5, color = \"firebrick\") +\n  scale_y_continuous(labels = label_dollar()) +\n  labs(title = \"Distribution of Home Sale Prices by Total Livable Area\", \n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Total Livable Area\", \n       y = \"Sale Price\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n**Interpretation:** The plot represents the relationship between the non-transformed target sale price and predictor total livable area. We can see that the relationship to be positive with evidence of heavy right-skew with the majority of data points clustered in the bottom-left with less than 3000 sq ft of area and \\$500,000 price. Also, we notice that although the relationship is positive, it does not appear to be linear, a violation of a crucial assumption in linear regression. As before, there is the presence of luxury homes as large outliers that can pull the regression line upward, which would create biased estimates on model coefficients.\n\n```{r}\nggplot(phl_sales_clean, aes(x = log(total_livable_area), log(sale_price))) +\n  geom_point(alpha = 0.075, size = 1) +\n  geom_smooth(method = \"lm\", se = FALSE, linetype = 5, color = \"firebrick\") +\n  scale_y_continuous(labels = label_dollar()) +\n  labs(title = \"Distribution of Log(Home Sale Prices) by Total Livable Area\", \n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Log(Total Livable Area)\", \n       y = \"Log(Sale Price)\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n**Interpretation:** By log-transforming both sale price and total livable area, we visualize a relationship that appears much more linear. As we saw before, there seem to be more variability in homes with smaller areas that are more common in this dataset. The transformation has more of a uniform, symmetric spread of points above and below the regression line. We can interpret this relationship as increasing the percentage of total livable area will lead to some constant increase in the percentage of sale price with this transformation. We should keep at mind that the non-constant variance is alarming for potential heteroskedasticity in our model. Again, through the log-transformation of our target variable, we observe a more linear relationship, strengthening the notion for the need for this transformation in our modeling phase.\n\n#### 4. Age (Sale Date - Year Built)\n\n```{r}\nggplot(phl_sales_clean, aes(x = age, y = sale_price)) +\n  geom_point(alpha = 0.076, size = 1) +\n  scale_y_continuous(labels = label_dollar()) +\n  labs(title = \"Distribution of Home Sale Prices by Age\", \n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Age\", \n       y = \"Sale Price\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n**Interpretation:** In the above plot, it does not reveal any significant relationship between sale price and home age. The main issue is that most of the data is clustered at the bottom of the figure at low sale prices regardless of age. There are some noticeable outliers along with increased variability for middle-aged homes around 75 to 125 years old. In general, it seems that there newer homes (lower age) demonstrate somewhat higher price levels on average. However, from this plot alone, it is difficult to verify.\n\n```{r}\nggplot(phl_sales_clean, aes(x = age, log(sale_price))) +\n  geom_point(alpha = 0.075, size = 1) +\n  geom_smooth(method = \"loess\", span = 0.75, se = FALSE, color = \"firebrick\") +\n  scale_y_continuous(labels = label_dollar()) +\n  labs(title = \"Distribution of Log(Home Sale Prices) by Age\", \n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Age\", \n       y = \"Log(Sale Price)\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n**Interpretation:** After doing the trick to log-transform sale price, we see an interesting shape that somewhat resembles a crucial theory we learned in lecture. This theory outlines that Age has a U-shaped effect on price. Newer homes are sought after due to recent construction with more modern amenities, whereas very old homes are considered to have historic value or charm. The middle-aged homes are therefore the least desirable homes that likely are not modernized with significant wear and tear without the allure of a historic home. While this theory makes sense, it somewhat breaks down for these middle aged homes as their sale prices experience much more variability, which would make our model more at risk of heteroskedasticity. This is likely due to a majority of samples in our dataset within this range whose sale price cannot be explained by age alone. Therefore, it is wise to proceed with caution with using the age variable in building our predictive model.\n\n```{r}\ndf_age_groups <- phl_sales_clean |>\n  mutate(\n    age_group = case_when(\n      age < 20 ~ \"New (<20 years)\",\n      age < 80 ~ \"Middle (20–80 years)\",\n      age >= 80 ~ \"Historic (>80 years)\"\n    ),\n    age_group = factor(age_group, levels = c(\"New (<20 years)\", \"Middle (20–80 years)\", \"Historic (>80 years)\"))\n  )\n\nggplot(df_age_groups, aes(age_group, log(sale_price))) +\n  geom_boxplot(fill = \"lightcyan2\", outlier.colour = \"firebrick\", outlier.alpha = 0.2) +\n  labs(\n    title = \"Distribution of Log(Sale Price) by Age Group\",\n    subtitle = \"Philadelphia Residential Sales in 2023–2024\",\n    x = \"Age Group\", y = \"log(Sale Price)\",\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n**Interpretation:** When we engineer a new age group feature, the U-shaped distribution does not appear to be valid in the case of our dataset. Using the age segmentations defined in class, it now appears as there is an inverse (negative) relationship between log(sale price) and age group, not a U-shape distribution. One hypothesis is that very old buildings in Philadelphia are too worn down or don't hold enough historic value to counteract its age. Whatever the reason may be, it seems that engineering a feature for age group is preferred over using age directly and to expect increasing age to a home to depreciate its value over time.\n\n### Price vs. spatial features\n\n```{r}\n\n```\n\n**Interpretation:**\n\n### One creative visualization\n\n```{r}\n\n```\n\n**Interpretation:**\n\n\n# PHASE 3: FEATURE ENGINEERING\n\n### Final Data Cleaning from Structural EDA\n\n```{r}\n# 99th percentile of sales prices to remove\nprice_99_perc <- quantile(phl_sales_clean$sale_price, 0.99, na.rm = TRUE)\n\n# Relevant columns to keep for modeling\nrel_columns <- c(\n    # Location / Shape\n    \"census_tract\", \"shape\", \"location\", \"zip_code\",\n    # Target\n    \"sale_price\", \"log_price\",\n    # Regressors (and potential ones)\n    \"total_livable_area\", \"log_total_livable_area\",\n    \"number_of_bedrooms\", \"number_of_bathrooms\",\n    \"year_built\", \"age\", \"age_group\",\n    \"interior_condition\", \"quality_grade\" \n  )\n\nphl_sales_final <- phl_sales_clean |>\n  filter(\n    # Remove top 1% of sale price (extreme outliers)\n    # This creates an upper bound of around $2 million rather than $6 million to further reduce outlier effects in modeling\n    sale_price < price_99_perc,\n    # Remove bathrooms > 7\n    number_of_bathrooms < 8,\n    # Remove bedrooms > 9\n    number_of_bedrooms < 10\n  )|>\n  mutate(\n    # Log of sale price\n    log_price = log(sale_price),\n    # Log of total livable area\n    log_total_livable_area = log(total_livable_area),\n    # Age group buckets (new, middle_age, historic)\n    age_group = case_when(\n      age < 20 ~ \"New (<20)\",\n      age <= 80 ~ \"Middle (20–80)\",\n      age > 80 ~ \"Historic (>80)\"\n    ),\n    # For modeling as dummy variables\n    age_group = factor(age_group, levels = c(\"New (<20)\", \"Middle (20–80)\", \"Historic (>80)\"))\n  ) |>\n  # Select relevant columns\n  select(any_of(rel_columns))\n```\n\n\n### Buffer-based features\n\n```{r}\n\n```\n\n### K-Nearest neighbors features\n\n```{r}\n\n```\n\n### Census variables\n\n```{r}\n\n```\n\n### Interaction terms\n\n```{r}\n\n```\n\n### Summary table\n\n```{r}\n\n```\n\n### Justification of feature engineered variables\n\n","srcMarkdownNoYaml":"\n\n```{r}\n#| echo: False\n# Load packages\nlibrary(tidycensus)\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(scales)\nlibrary(RColorBrewer)\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(tigris)\nlibrary(patchwork)\nlibrary(here)\n\noptions(tigris_use_cache = TRUE, tigris_progress = FALSE) \n```\n\n# PHASE 1: DATA PREPARATION\n\n## 1.1 Load and Philadelphia house sales data\n```{r}\n# Load Philly Property Sales data\nphl_sales <- read_csv(\"../data/raw/opa_properties_public.csv\", show_col_types = FALSE)\n```\n\n### Filter to residential properties, 2023-2024 sales\n```{r}\n# Check data types\n# glimpse(phl_sales)\n\nphl_sales_res_23_24 <- phl_sales |>\n  filter(\n    category_code == 1, # Residential\n    year(sale_date) %in% c(2023, 2024), # 2023-24 sales\n    !is.na(category_code) & !is.na(sale_date) # Handle nulls\n  )\n```\n\n### Remove obvious errors\n```{r}\nphl_sales_clean <- phl_sales_res_23_24 |>\n  filter(\n    # Some sale_price are unrealistically too low ($0, $1 etc.)\n    sale_price >= 10000,\n    # Exclude homes with 0 bathrooms\n    number_of_bathrooms > 0,\n    # Some areas are unrealistically low (0, 1, etc.)\n    total_area > 1,\n    # Some 0's remain in total_liveable_area after first area filter\n    total_livable_area > 0,\n    # Filter our unrealistic year built\n    year_built >= 1750\n    ) \n```\n\n### Handle missing values\n\n```{r}\n# Check how many features have NA values\n# sum(is.na(phl_sales_clean$number_of_bedrooms))\n# sum(is.na(phl_sales_clean$number_of_bathrooms))\n# sum(is.na(phl_sales_clean$total_livable_area))\n# sum(is.na(phl_sales_clean$year_built))\n\n# Remove the 2 observations with NA values for number of bedrooms\nphl_sales_clean <- phl_sales_clean |>\n  filter(\n    !is.na(number_of_bedrooms)\n  )\n```\n\n### Preliminary Feature Engineering: Age = sale date - year built\n```{r}\nphl_sales_clean <- phl_sales_clean |>\n  mutate(\n    sale_year = year(sale_date),\n    age = sale_year - year_built\n  )\n```\n\n### Document all cleaning decisions\n\n\n- Our methodology for cleaning the Philadelphia home sales data is to focus on the features used in our model. As a group, we decided on the following independent variables to consider in our data exploration and model building to be: number of bathrooms, number of bedrooms, total livable area, and year built. We recognize that there is some risk of collinearity between these structural features, which will later be monitored and addressed if needed in the model building stage. Additionally, we also had to clean the sales price column since this is the variable we aim to predict in our model.\n\n\n- Filter for only **residential properties** & **sales made in 2023-24** (per instructions).\n\n\n- Filter for **realistic sales price** >= $10,000.\n\n\n- Filter for houses with **at least 1 bathroom**. We will keep observations where **number of bedrooms = 0** as this likely signifies a studio apartment. However, it is not feasible for homes to have zero bathrooms, so we will enforce a constraint that a home must have at least 1 bathroom to preserve data integrity.\n\n\n- Filter for **realistic total area** > 1 sq ft & **realistic total livable area** > 0 sq ft.\n\n\n- Filter for **year built** >= 1750 (some homes were built in year 0).\n\n\n- **Handle missing values:** We removed any missing values in our dependent variable of sales price, since it is crucial we have a true and accurate measure for prediction. We also checked which of our predictor variables had NA values after filtering. Only number of bedrooms had 2 remaining NA values. The rest had no NA values. To remedy this, we will remove the 2 observations from our data. Note, if there was substantial missing values in our predictors, we could use strategies such as imputing the NA values with the mean or median to use when building our model. \n\n\n- **Preliminary feature engineering:** Rather than using year built in our Automated Valuation Model, it makes more sense to create a new variable **age** that is equal to the sale date minus the year built. The **age** variable is often easier to interpret in exploratory plots with the newer houses appearing on the left and older ones on the right. This is primarily a stylistic preference: the overall pattern of the data will remain the same but mirrored.\n\n\n## 1.2 Load Secondary Data\n\n### Census\n\nPurpose: Pull demographic and housing data at the block group level for Philadelphia from the 2023 5-year ACS. This data will provide predictors for neighborhood characteristics in our modeling.\n\nVariables Collected:\n\nMedian household income (B19013)\n\nPercentage of family households (B11001)\n\nEducation attainment: percent of population 25+ with a bachelor’s degree or higher (B15003)\n\nHousing vacancy rate (B25002)\n\nRacial composition: percent white (B02001)\n\n```{r api key,eval=FALSE, include=FALSE}\n\n# This Block is the code that I used to Pull and Manipulate the Census Data. I condensed it and included it in one block for the team's reference. This output files have been uploaded to the project and will be pulled in the next code block to reduce computation.\n\ncensus_api_key <- (\"8deb926015351433bef092c55a5e8a90573283bd\")\n\n\n#philly-tract-data\n\n# Define parameters\nmy_state  <- \"Pennsylvania\"\nmy_county <- \"Philadelphia\"\nacs_year  <- 2023  # latest available 5-year ACS (2019–2023)\n\n# Median Household income\nincome <- get_acs(\n  geography = \"block group\",\n  state = my_state,\n  county = my_county,\n  table = \"B19013\",\n  year = acs_year,\n  survey = \"acs5\"\n) %>%\n  select(GEOID, median_income = estimate)\n\n# Percentage of family households\nhouseholds <- get_acs(\n  geography = \"block group\",\n  state = my_state,\n  county = my_county,\n  table = \"B11001\",\n  year = acs_year,\n  survey = \"acs5\"\n) %>%\n  select(GEOID, variable, estimate) %>%\n  tidyr::pivot_wider(names_from = variable, values_from = estimate) %>%\n  mutate(\n    family_hh = B11001_002,\n    total_hh  = B11001_001\n  ) %>%\n  select(GEOID, family_hh, total_hh)\n\n# Education (percent bachelor’s or higher)\neducation <- get_acs(\n  geography = \"block group\",\n  state = my_state,\n  county = my_county,\n  table = \"B15003\",\n  year = acs_year,\n  survey = \"acs5\") %>%\n  select(GEOID, variable, estimate) %>%\n  tidyr::pivot_wider(names_from = variable, values_from = estimate) %>%\n  mutate(\n    total_25plus = B15003_001,\n    bachelors_plus = B15003_022 + B15003_023 + B15003_024 + B15003_025,\n    pct_bachelors = 100 * bachelors_plus / total_25plus\n  ) %>%\n  select(GEOID, pct_bachelors)\n\n# Percent of vacant homes = number vacant/total homes\nvacancy <- get_acs(\n  geography = \"block group\",\n  state = my_state,\n  county = my_county,\n  table = \"B25002\",\n  year = acs_year,\n  survey = \"acs5\"\n) %>%\n  select(GEOID, variable, estimate) %>%\n  tidyr::pivot_wider(names_from = variable, values_from = estimate) %>%\n  mutate(\n    total_units = B25002_001,\n    vacant_units = B25002_003,\n    pct_vacant = 100 * vacant_units / total_units\n  ) %>%\n  select(GEOID, pct_vacant)\n\n# retrieving percent white for block group\ndemographics <- get_acs(\n  geography = \"block group\",\n  state = my_state,\n  county = my_county,\n  table = \"B02001\",\n  year = acs_year,\n  survey = \"acs5\") %>%\n  select(GEOID, variable, estimate) %>%\n  tidyr::pivot_wider(names_from = variable, values_from = estimate) %>%\n  mutate(\n    total_pop = B02001_001,\n    white_pop = B02001_002,\n    pct_white = 100 * white_pop / total_pop\n  ) %>%\n  select(GEOID, pct_white)\n\nphilly_blockgroup <- income %>%\n  left_join(households, by = \"GEOID\") %>%\n  left_join(education, by = \"GEOID\") %>%\n  left_join(vacancy, by = \"GEOID\") %>%\n  left_join(demographics, by = \"GEOID\")\n\nhead(philly_blockgroup)\n\n#Block Group Geometry Pull\nphilly_bg_sf <- get_acs(\n  geography = \"block group\",\n  state = \"PA\",\n  county = \"Philadelphia\",\n  table = \"B19013\",\n  year = 2023,\n  survey = \"acs5\",\n  geometry = TRUE)\n\nhead(philly_bg_sf)\n\n# Geometry - Cenus Data Merge\nphilly_bg_map <- philly_bg_sf %>%\n  left_join(philly_blockgroup, by = \"GEOID\")\n```\n\n#### Load Philly Census Data from Previously Retrieved Files\n\n```{r}\n# Relative to project root\ncensus_path <- here(\"data\", \"Philly Census\")\n\ncensus_csv_path <- file.path(census_path, \"philly_blockgroups_metrics.csv\")\ncensus_shp_path <- file.path(census_path, \"philly_blockgroups.shp\")\n\n# Csv with Block Group Geo IDs and metrics\nphilly_blockgroup <- read_csv(census_csv_path, show_col_types = FALSE)\n\n# Shp File including geometry\nphilly_bg_sf <- st_read(census_shp_path, quiet = TRUE)\n```\n\n#### Observe Summary Statistics from target metrics.\n\n```{r}\nnumeric_vars <- c(\"median_income\", \"pct_white\", \"pct_bachelors\", \"pct_vacant\")\nphilly_blockgroup %>%\n  select(all_of(numeric_vars)) %>%\n  summary()\n```\nA quick check of the census variables reveals some missing values and lower than epected values in median income. We will note this information but retain the missing values for now to maintain the full pitcure of census blocks.\n\n\n### Cleaning Methodology (Census)\n\nMedian income: Selected only the estimate column and renamed it for clarity.\n\nHousehold composition: Pivoted ACS table to wide format, then calculated total households and family households.\n\nEducation: Pivoted to wide format, summed relevant categories to compute percent of population with a bachelor’s degree or higher.\n\nVacancy: Pivoted to wide format, calculated percent of homes vacant (vacant_units / total_units * 100).\n\nRacial composition: Pivoted to wide format, computed percent white.\n\nMerging: Combined all datasets by GEOID to create a single dataframe philly_blockgroup with all variables.\n\nGeometry: Pulled block group shapefiles with ACS geometry and merged with philly_blockgroup to create philly_bg_map.\n\n### Neighborhood (Polygon)\n\nReading in Philadelphia Neighborhoods as a shp object. This will allow us to aggregate data on neighborhoods to identify catagorical metrics.\n\n```{r}\nneighborhood_folder <- here(\"data\", \"philadelphia-neighborhoods\")\nneighborhood_path   <- file.path(neighborhood_folder, \"philadelphia-neighborhoods.shp\")\n\n# Read the shapefile\nphilly_neighborhoods <- st_read(neighborhood_path, quiet = TRUE)\n\nhead(philly_neighborhoods)\n```\n\n\n### City Centers (Amenities)\n\n```{r}\n\n```\n\n### Education\n\nWe used two datasets from OpenDataPhilly.com to identify schools geolocation and populated the metrics off Attendance percent and Withdrawal volumes from those schools.\n\n```{r}\n# Relative to project root\neducation_path <- here(\"data\", \"Education\")\n\neducation_csv_path <- file.path(education_path, \"philadelphia_schools.csv\")\neducation_shp_path <- file.path(education_path, \"Schools Shape\", \"Schools.shp\")\n\n# Csv with School Names and metrics\nphilly_schools <- read_csv(education_csv_path, show_col_types = FALSE)\n\n# Shp File including geometry\nphilly_schools_sf <- st_read(education_shp_path, quiet = TRUE)\n```\n\nWe joined the csv file containing the metrics with the shp file containing geoloaction.\n\n```{r}\n# Joining Schools csv metrics to shp file. Joined on 'location_i' (shp) and 'School_code (csv)\n# Keeping metrics for Attendance and Withdrawals\n\n# Select relevant metrics from CSV\nschool_metrics <- philly_schools %>%\n  select(School_code, Attendance, Withdrawals) %>%\n  mutate(School_code = as.character(School_code))\n\nphilly_schools_sf <- philly_schools_sf %>%\n  left_join(school_metrics,\n            by = c(\"location_i\" = \"School_code\"))\n```\n```{r}\nphilly_schools_sf_clean <- philly_schools_sf %>%\n  filter(!is.na(Attendance) & !is.na(Withdrawals))\n```\n```{r}\nnames(philly_schools_sf_clean)\nnrow(philly_schools_sf_clean)\n```\nOnce joined, we dropped rows that did not have values in Attendance and Withdrawal. This resulted in 204 public schools and their metrics located in Philadelphia City Limits.\n\n### Joining data together\n\n```{r}\n\n```\n\n\n# PHASE 2: EXPLORATORY DATA ANALYSIS\n\n### Distribution of sale prices (histogram)\n\n```{r}\n# Calculate the median / mean to plot\nprice_median <- median(phl_sales_clean$sale_price, na.rm = TRUE)\n\nggplot(phl_sales_clean, aes(sale_price)) +\n  geom_histogram(bins = 60, fill = \"darkseagreen3\", color = \"black\") +\n  geom_vline(xintercept = price_median, linetype = 5) +\n  annotate(\"text\",\n           x = price_median, \n           y = 6300, \n           label = \"Median\",\n           hjust = -0.2, \n           color = \"black\", \n           size = 3) +\n  scale_x_continuous(labels = label_dollar()) +\n  labs(title = \"Distribution of Home Sale Prices\",\n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Sale Price\",\n       y = \"Count\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n**Interpretation:** The histogram plot above shows the full distribution of home sale prices for residential properties in 2023-2024 from our cleaned dataset. The data is extremely right-skewed, highlighting a majority of prices under \\$500,000 with a long tail of more expensive homes thereafter. The main issue with the extreme outliers of home prices exceeding \\$5 million that make the visibility of this plot hard to interpret. Also, there are major gaps at higher sales prices as we see the data become more spread out, further indicating the presence of outliers. Therefore, to remedy this, we will plot a second histogram of the price distribution, excluding the top 5% of sales prices from the original cleaned dataset.\n\n```{r}\n# Create new df, filtering out the top 5% of house prices (outliers)\nprice_95_perc <- quantile(phl_sales_clean$sale_price, 0.95, na.rm = TRUE)\ndf_95_exclude <- filter(phl_sales_clean, sale_price <= price_95_perc)\n\n# Calculate the median / mean to plot from trimmed distribution\nprice_median_95_exc <- median(df_95_exclude$sale_price, na.rm = TRUE)\nprice_mean_95_exc <- mean(df_95_exclude$sale_price, na.rm = TRUE)\n\nggplot(df_95_exclude, aes(sale_price)) +\n  geom_histogram(bins = 20, fill = \"darkseagreen3\", color = \"black\") +\n  geom_vline(xintercept = price_mean_95_exc, linetype = 5) +\n  geom_vline(xintercept = price_median_95_exc, linetype = 5) +\n  annotate(\"text\",\n           x = price_mean_95_exc,\n           y = 2400,\n           label = \"Mean\", \n           hjust = - 0.1, \n           color = \"black\", \n           size = 3) +\n  annotate(\"text\",\n           x = price_median_95_exc, \n           y = 2450, \n           label = \"Median\",\n           hjust = 1.25, \n           color = \"black\", \n           size = 3) +\n  scale_x_continuous(labels = label_dollar()) +\n  labs(\n    title = \"Distribution of Home Sale Prices\",\n    subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n    caption = \"Histogram and median/mean statistics were computed on filtered sample (sale price ≤ 95th percentile) for better visibility.\",\n    x = \"Sale Price\",\n    y = \"Count\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  ) \n```\n\n**Interpretation:** In this revised histogram, we get a much better sense of how the sales prices are distributed without the presence of extreme outliers. As we saw before, the data is definitely right-skewed since the median (\\$235,250) is less than the mean (\\$322,231) even when removing large outliers from the top 5% of the distribution. We can visualize that the standard housing market in Philadelphia from 2023-2024 ranges between \\$0 and \\$800,000. The distribution has a single peak around \\$200,000, indicating that it is unimodal with a typical (or most common) home sale price in the realm of \\$150,000 to \\$250,000. This is an indication that it may be best to omit these significant outliers from our dataset when building our model for home sale price prediction. The homes on the higher end of the sale price distribution are determined by a combination of structural features (such total livable area) and spatial features (such as nearby city centers) that drive up the prices of these homes. The goal of this study is to determine what features, both structural and spatial, are significant in predicting home sale prices in Philadelphia and create an accurate model to help policy makers in valuating property tax assessments.\n\n### Geographic distribution (map)\n\n```{r}\n\n```\n\n**Interpretation:**\n\n### Price vs. structural features\n\n#### 1. Number of Bathrooms\n\n```{r}\nggplot(phl_sales_clean, aes(x = factor(number_of_bathrooms), y = sale_price)) +\n  geom_boxplot(fill = \"lightcyan2\", outlier.color = \"firebrick\", outlier.alpha = 0.2) +\n  scale_y_continuous(labels = scales::label_dollar()) +\n  labs(title = \"Distribution of Home Sale Prices by Number of Bathrooms\", \n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Bathrooms\", \n       y = \"Sale Price\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n**Interpretation:** Since number of bathrooms is a discrete variable, a scatter plot is not suitable to visualize this predictor's relationship with the target variable of sale price; therefore, we opted to use box plots instead. In this first plot, we see a distinct positive relationship between number of bathrooms and home sale price. Intuitively, this makes sense since homes with more bathrooms should on average sell at higher prices. Another trend is that there are more outliers in homes with less bathrooms (between 1 and 3). These outliers are likely due to external spatial factors such as neighborhoods. Housing prices tend to surge in highly desirable neighborhoods such as Rittenhouse Square, which explains the presence of many outliers plotted above the upper bound of these boxplots. Another trend is that variance of sale prices begins to significantly widen for homes with more than 3 bedrooms. This suggests that larger homes with more bathrooms experience more price dispersion relative to those with less bathrooms. Lastly, it is worth noting that there are very few observations of homes with 8 or 12 bathrooms, indicating that it would be beneficial to remove them from our dataset to better capture the true relationship between price and number of bathrooms.\n\n```{r}\nggplot(phl_sales_clean, aes(x = factor(number_of_bathrooms), y = log(sale_price))) +\n  geom_boxplot(fill = \"lightcyan2\", outlier.color = \"firebrick\", outlier.alpha = 0.2) +\n  scale_y_continuous(labels = scales::label_dollar()) +\n  labs(title = \"Distribution of Log(Home Sale Prices) by Number of Bathrooms\", \n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Bathrooms\", \n       y = \"Log(Sale Price)\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n**Interpretation:** In addition, we also plotted with the y-axis transformed to the log of sales price. We notice that there is still a positive relationship that appears more linear than the first plot. The log transformation helps reduce the effect of extreme outliers by compressing the distribution of house sale prices. This transformation also serves to center the distributions as noted by the presence of both positive and negative outliers. These benefits suggest that log-transforming our target variable for a linear regression is the best suitable method to yield an accurate model. \n\n#### 2. Number of Bedrooms\n\n```{r}\nggplot(phl_sales_clean, aes(x = factor(number_of_bedrooms), y = sale_price)) +\n  geom_boxplot(fill = \"lightcyan2\", outlier.color = \"firebrick\", outlier.alpha = 0.2) +\n  scale_y_continuous(labels = scales::label_dollar()) +\n  labs(title = \"Distribution of Home Sale Prices by Number of Bedrooms\", \n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Bedrooms\", \n       y = \"Sale Price\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n**Interpretation:** The above plot to measure the relationship between home sale price and number of bedrooms is positive, indicating that homes with more bedrooms tend to sell at higher prices. However, this relationship looks significantly less strong than the relationship between sale price and number of bathrooms. We observe many outliers across homes with various bedroom sizes, most notably those with 2 - 5 bedrooms. The intuition is that these size households are more likely to be sold on the market with higher variability in sales prices, particularly in the upper tail, demonstrating right-skew. These high outliers represent luxury properties that sell for abnormally high sale prices due to other external variables like neighborhood, size etc. Again, we have a small number of very large homes with 10, 11, and 12 bedrooms that are candidates for removal before building our model.\n\n```{r}\nggplot(phl_sales_clean, aes(x = factor(number_of_bedrooms), y = log(sale_price))) +\n  geom_boxplot(fill = \"lightcyan2\", outlier.color = \"firebrick\", outlier.alpha = 0.2) +\n  scale_y_continuous(labels = scales::label_dollar()) +\n  labs(title = \"Distribution of Log(Home Sale Prices) by Number of Bedrooms\", \n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Bedrooms\", \n       y = \"Log(Sale Price)\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n**Interpretation:** As before, we can log-transform the target variable log(sale price) to better visualize the relationship with number of bedrooms. We still see a positive relationship that appears more linear than in our earlier plot. As before, the log-transformation stabilizes the variance to mitigate outliers and centers the data demonstrated by outliers at both the upper and lower tails. The strength of the relationship still appears to be not as obvious as with the number of bathrooms. In other words, number of bathrooms may be a more suitable predictor of sale price from these EDA observations. To avoid the risk of multicollinearity, we will keep this finding in mind when determining what structural features should be included in our final model.\n\n#### 3. Total Livable Area\n\n```{r}\nggplot(phl_sales_clean, aes(x = total_livable_area, sale_price)) +\n  geom_point(alpha = 0.1, size = 1) +\n  geom_smooth(method = \"lm\", se = FALSE, linetype = 5, color = \"firebrick\") +\n  scale_y_continuous(labels = label_dollar()) +\n  labs(title = \"Distribution of Home Sale Prices by Total Livable Area\", \n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Total Livable Area\", \n       y = \"Sale Price\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n**Interpretation:** The plot represents the relationship between the non-transformed target sale price and predictor total livable area. We can see that the relationship to be positive with evidence of heavy right-skew with the majority of data points clustered in the bottom-left with less than 3000 sq ft of area and \\$500,000 price. Also, we notice that although the relationship is positive, it does not appear to be linear, a violation of a crucial assumption in linear regression. As before, there is the presence of luxury homes as large outliers that can pull the regression line upward, which would create biased estimates on model coefficients.\n\n```{r}\nggplot(phl_sales_clean, aes(x = log(total_livable_area), log(sale_price))) +\n  geom_point(alpha = 0.075, size = 1) +\n  geom_smooth(method = \"lm\", se = FALSE, linetype = 5, color = \"firebrick\") +\n  scale_y_continuous(labels = label_dollar()) +\n  labs(title = \"Distribution of Log(Home Sale Prices) by Total Livable Area\", \n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Log(Total Livable Area)\", \n       y = \"Log(Sale Price)\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n**Interpretation:** By log-transforming both sale price and total livable area, we visualize a relationship that appears much more linear. As we saw before, there seem to be more variability in homes with smaller areas that are more common in this dataset. The transformation has more of a uniform, symmetric spread of points above and below the regression line. We can interpret this relationship as increasing the percentage of total livable area will lead to some constant increase in the percentage of sale price with this transformation. We should keep at mind that the non-constant variance is alarming for potential heteroskedasticity in our model. Again, through the log-transformation of our target variable, we observe a more linear relationship, strengthening the notion for the need for this transformation in our modeling phase.\n\n#### 4. Age (Sale Date - Year Built)\n\n```{r}\nggplot(phl_sales_clean, aes(x = age, y = sale_price)) +\n  geom_point(alpha = 0.076, size = 1) +\n  scale_y_continuous(labels = label_dollar()) +\n  labs(title = \"Distribution of Home Sale Prices by Age\", \n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Age\", \n       y = \"Sale Price\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n**Interpretation:** In the above plot, it does not reveal any significant relationship between sale price and home age. The main issue is that most of the data is clustered at the bottom of the figure at low sale prices regardless of age. There are some noticeable outliers along with increased variability for middle-aged homes around 75 to 125 years old. In general, it seems that there newer homes (lower age) demonstrate somewhat higher price levels on average. However, from this plot alone, it is difficult to verify.\n\n```{r}\nggplot(phl_sales_clean, aes(x = age, log(sale_price))) +\n  geom_point(alpha = 0.075, size = 1) +\n  geom_smooth(method = \"loess\", span = 0.75, se = FALSE, color = \"firebrick\") +\n  scale_y_continuous(labels = label_dollar()) +\n  labs(title = \"Distribution of Log(Home Sale Prices) by Age\", \n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Age\", \n       y = \"Log(Sale Price)\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n**Interpretation:** After doing the trick to log-transform sale price, we see an interesting shape that somewhat resembles a crucial theory we learned in lecture. This theory outlines that Age has a U-shaped effect on price. Newer homes are sought after due to recent construction with more modern amenities, whereas very old homes are considered to have historic value or charm. The middle-aged homes are therefore the least desirable homes that likely are not modernized with significant wear and tear without the allure of a historic home. While this theory makes sense, it somewhat breaks down for these middle aged homes as their sale prices experience much more variability, which would make our model more at risk of heteroskedasticity. This is likely due to a majority of samples in our dataset within this range whose sale price cannot be explained by age alone. Therefore, it is wise to proceed with caution with using the age variable in building our predictive model.\n\n```{r}\ndf_age_groups <- phl_sales_clean |>\n  mutate(\n    age_group = case_when(\n      age < 20 ~ \"New (<20 years)\",\n      age < 80 ~ \"Middle (20–80 years)\",\n      age >= 80 ~ \"Historic (>80 years)\"\n    ),\n    age_group = factor(age_group, levels = c(\"New (<20 years)\", \"Middle (20–80 years)\", \"Historic (>80 years)\"))\n  )\n\nggplot(df_age_groups, aes(age_group, log(sale_price))) +\n  geom_boxplot(fill = \"lightcyan2\", outlier.colour = \"firebrick\", outlier.alpha = 0.2) +\n  labs(\n    title = \"Distribution of Log(Sale Price) by Age Group\",\n    subtitle = \"Philadelphia Residential Sales in 2023–2024\",\n    x = \"Age Group\", y = \"log(Sale Price)\",\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n**Interpretation:** When we engineer a new age group feature, the U-shaped distribution does not appear to be valid in the case of our dataset. Using the age segmentations defined in class, it now appears as there is an inverse (negative) relationship between log(sale price) and age group, not a U-shape distribution. One hypothesis is that very old buildings in Philadelphia are too worn down or don't hold enough historic value to counteract its age. Whatever the reason may be, it seems that engineering a feature for age group is preferred over using age directly and to expect increasing age to a home to depreciate its value over time.\n\n### Price vs. spatial features\n\n```{r}\n\n```\n\n**Interpretation:**\n\n### One creative visualization\n\n```{r}\n\n```\n\n**Interpretation:**\n\n\n# PHASE 3: FEATURE ENGINEERING\n\n### Final Data Cleaning from Structural EDA\n\n```{r}\n# 99th percentile of sales prices to remove\nprice_99_perc <- quantile(phl_sales_clean$sale_price, 0.99, na.rm = TRUE)\n\n# Relevant columns to keep for modeling\nrel_columns <- c(\n    # Location / Shape\n    \"census_tract\", \"shape\", \"location\", \"zip_code\",\n    # Target\n    \"sale_price\", \"log_price\",\n    # Regressors (and potential ones)\n    \"total_livable_area\", \"log_total_livable_area\",\n    \"number_of_bedrooms\", \"number_of_bathrooms\",\n    \"year_built\", \"age\", \"age_group\",\n    \"interior_condition\", \"quality_grade\" \n  )\n\nphl_sales_final <- phl_sales_clean |>\n  filter(\n    # Remove top 1% of sale price (extreme outliers)\n    # This creates an upper bound of around $2 million rather than $6 million to further reduce outlier effects in modeling\n    sale_price < price_99_perc,\n    # Remove bathrooms > 7\n    number_of_bathrooms < 8,\n    # Remove bedrooms > 9\n    number_of_bedrooms < 10\n  )|>\n  mutate(\n    # Log of sale price\n    log_price = log(sale_price),\n    # Log of total livable area\n    log_total_livable_area = log(total_livable_area),\n    # Age group buckets (new, middle_age, historic)\n    age_group = case_when(\n      age < 20 ~ \"New (<20)\",\n      age <= 80 ~ \"Middle (20–80)\",\n      age > 80 ~ \"Historic (>80)\"\n    ),\n    # For modeling as dummy variables\n    age_group = factor(age_group, levels = c(\"New (<20)\", \"Middle (20–80)\", \"Historic (>80)\"))\n  ) |>\n  # Select relevant columns\n  select(any_of(rel_columns))\n```\n\n\n### Buffer-based features\n\n```{r}\n\n```\n\n### K-Nearest neighbors features\n\n```{r}\n\n```\n\n### Census variables\n\n```{r}\n\n```\n\n### Interaction terms\n\n```{r}\n\n```\n\n### Summary table\n\n```{r}\n\n```\n\n### Justification of feature engineered variables\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"appendix.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.24","theme":"cosmo","title":"Technical Appendix"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}