[
  {
    "objectID": "appendix/appendix.html",
    "href": "appendix/appendix.html",
    "title": "Technical Appendix",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'scales'\n\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\nTo enable caching of data, set `options(tigris_use_cache = TRUE)`\nin your R script or .Rprofile.\n\nhere() starts at /Users/jack/Documents/GitHub/MUSA5080-Midterm"
  },
  {
    "objectID": "appendix/appendix.html#load-and-philadelphia-house-sales-data",
    "href": "appendix/appendix.html#load-and-philadelphia-house-sales-data",
    "title": "Technical Appendix",
    "section": "1.1 Load and Philadelphia house sales data",
    "text": "1.1 Load and Philadelphia house sales data\n\n# Load Philly Property Sales data\nphl_sales &lt;- read_csv(\"../data/raw/opa_properties_public.csv\", show_col_types = FALSE)\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\n\nFilter to residential properties, 2023-2024 sales\n\n# Check data types\n# glimpse(phl_sales)\n\nphl_sales_res_23_24 &lt;- phl_sales |&gt;\n  filter(\n    category_code == 1, # Residential\n    year(sale_date) %in% c(2023, 2024), # 2023-24 sales\n    !is.na(category_code) & !is.na(sale_date) # Handle nulls\n  )\n\n\n\nRemove obvious errors\n\nphl_sales_clean &lt;- phl_sales_res_23_24 |&gt;\n  filter(\n    # Some sale_price are unrealistically too low ($0, $1 etc.)\n    sale_price &gt;= 10000,\n    # Exclude homes with 0 bathrooms\n    number_of_bathrooms &gt; 0,\n    # Some areas are unrealistically low (0, 1, etc.)\n    total_area &gt; 1,\n    # Some 0's remain in total_liveable_area after first area filter\n    total_livable_area &gt; 0,\n    # Filter our unrealistic year built\n    year_built &gt;= 1750\n    ) \n\n\n\nHandle missing values\n\n# Check how many features have NA values\n# sum(is.na(phl_sales_clean$number_of_bedrooms))\n# sum(is.na(phl_sales_clean$number_of_bathrooms))\n# sum(is.na(phl_sales_clean$total_livable_area))\n# sum(is.na(phl_sales_clean$year_built))\n\n# Remove the 2 observations with NA values for number of bedrooms\nphl_sales_clean &lt;- phl_sales_clean |&gt;\n  filter(\n    !is.na(number_of_bedrooms)\n  )\n\n\n\nDocument all cleaning decisions\n\nOur methodology for cleaning the Philadelphia home sales data is to focus on the features used in our model. As a group, we decided on the following independent variables to consider in our data exploration and model building to be: number of bathrooms, number of bedrooms, total livable area, and year built. We recognize that there is some risk of collinearity between these structural features, which will later be monitored and addressed if needed in the model building stage. Additionally, we also had to clean the sales price column since this is the variable we aim to predict in our model.\nFilter for only residential properties & sales made in 2023-24 (per instructions).\nFilter for realistic sales price &gt;= $10,000.\nFilter for houses with at least 1 bathroom. We will keep observations where number of bedrooms = 0 as this likely signifies a studio apartment. However, it is not feasible for homes to have zero bathrooms, so we will enforce a constraint that a home must have at least 1 bathroom to preserve data integrity.\nFilter for realistic total area &gt; 1 sq ft & realistic total livable area &gt; 0 sq ft.\nFilter for year built &gt;= 1750 (some homes were built in year 0).\nHandle missing values: We removed any missing values in our dependent variable of sales price, since it is crucial we have a true and accurate measure for prediction. We also checked which of our predictor variables had NA values after filtering. Only number of bedrooms had 2 remaining NA values. The rest had no NA values. To remedy this, we will remove the 2 observations from our data. Note, if there was substantial missing values in our predictors, we could use strategies such as imputing the NA values with the mean or median to use when building our model."
  },
  {
    "objectID": "appendix/appendix.html#load-secondary-data",
    "href": "appendix/appendix.html#load-secondary-data",
    "title": "Technical Appendix",
    "section": "1.2 Load Secondary Data",
    "text": "1.2 Load Secondary Data\n\nCensus\n\n\nNeighborhood (Polygon)\n\n\nCity Centers (Amenities)\n\n\nEducation\n\n\nJoining data together"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Philadelphia Housing Price Prediction",
    "section": "",
    "text": "Project Overview:\n\nMembers: Jack Bader, Date: October 27, 2025"
  }
]