[
  {
    "objectID": "appendix/appendix.html",
    "href": "appendix/appendix.html",
    "title": "Technical Appendix",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.2\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'scales'\n\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\n\nLinking to GEOS 3.13.1, GDAL 3.11.0, PROJ 9.6.0; sf_use_s2() is TRUE\n\nTo enable caching of data, set `options(tigris_use_cache = TRUE)`\nin your R script or .Rprofile.\n\nhere() starts at C:/Users/jcahi/OneDrive/Desktop/MUSA 5080/Midterm/MUSA5080-Midterm"
  },
  {
    "objectID": "appendix/appendix.html#load-and-philadelphia-house-sales-data",
    "href": "appendix/appendix.html#load-and-philadelphia-house-sales-data",
    "title": "Technical Appendix",
    "section": "1.1 Load and Philadelphia house sales data",
    "text": "1.1 Load and Philadelphia house sales data\n\n# Load Philly Property Sales data\nphl_sales &lt;- read_csv(\"../data/raw/opa_properties_public.csv\", show_col_types = FALSE)\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\n\nFilter to residential properties, 2023-2024 sales\n\n# Check data types\n# glimpse(phl_sales)\n\nphl_sales_res_23_24 &lt;- phl_sales |&gt;\n  filter(\n    category_code == 1, # Residential\n    year(sale_date) %in% c(2023, 2024), # 2023-24 sales\n    !is.na(category_code) & !is.na(sale_date) # Handle nulls\n  )\n\n\n\nRemove obvious errors\n\nphl_sales_clean &lt;- phl_sales_res_23_24 |&gt;\n  filter(\n    # Some sale_price are unrealistically too low ($0, $1 etc.)\n    sale_price &gt;= 10000,\n    # Exclude homes with 0 bathrooms\n    number_of_bathrooms &gt; 0,\n    # Some areas are unrealistically low (0, 1, etc.)\n    total_area &gt; 1,\n    # Some 0's remain in total_liveable_area after first area filter\n    total_livable_area &gt; 0,\n    # Filter our unrealistic year built\n    year_built &gt;= 1750\n    ) \n\n\n\nHandle missing values\n\n# Check how many features have NA values\n# sum(is.na(phl_sales_clean$number_of_bedrooms))\n# sum(is.na(phl_sales_clean$number_of_bathrooms))\n# sum(is.na(phl_sales_clean$total_livable_area))\n# sum(is.na(phl_sales_clean$year_built))\n\n# Remove the 2 observations with NA values for number of bedrooms\nphl_sales_clean &lt;- phl_sales_clean |&gt;\n  filter(\n    !is.na(number_of_bedrooms)\n  )\n\n\n\nPreliminary Feature Engineering: Age = sale date - year built\n\nphl_sales_clean &lt;- phl_sales_clean |&gt;\n  mutate(\n    sale_year = year(sale_date),\n    age = sale_year - year_built\n  )\n\n\n\nDocument all cleaning decisions\n\nOur methodology for cleaning the Philadelphia home sales data is to focus on the features used in our model. As a group, we decided on the following independent variables to consider in our data exploration and model building to be: number of bathrooms, number of bedrooms, total livable area, and year built. We recognize that there is some risk of collinearity between these structural features, which will later be monitored and addressed if needed in the model building stage. Additionally, we also had to clean the sales price column since this is the variable we aim to predict in our model.\nFilter for only residential properties & sales made in 2023-24 (per instructions).\nFilter for realistic sales price &gt;= $10,000.\nFilter for houses with at least 1 bathroom. We will keep observations where number of bedrooms = 0 as this likely signifies a studio apartment. However, it is not feasible for homes to have zero bathrooms, so we will enforce a constraint that a home must have at least 1 bathroom to preserve data integrity.\nFilter for realistic total area &gt; 1 sq ft & realistic total livable area &gt; 0 sq ft.\nFilter for year built &gt;= 1750 (some homes were built in year 0).\nHandle missing values: We removed any missing values in our dependent variable of sales price, since it is crucial we have a true and accurate measure for prediction. We also checked which of our predictor variables had NA values after filtering. Only number of bedrooms had 2 remaining NA values. The rest had no NA values. To remedy this, we will remove the 2 observations from our data. Note, if there was substantial missing values in our predictors, we could use strategies such as imputing the NA values with the mean or median to use when building our model.\nPreliminary feature engineering: Rather than using year built in our Automated Valuation Model, it makes more sense to create a new variable age that is equal to the sale date minus the year built. The age variable is often easier to interpret in exploratory plots with the newer houses appearing on the left and older ones on the right. This is primarily a stylistic preference: the overall pattern of the data will remain the same but mirrored."
  },
  {
    "objectID": "appendix/appendix.html#load-secondary-data",
    "href": "appendix/appendix.html#load-secondary-data",
    "title": "Technical Appendix",
    "section": "1.2 Load Secondary Data",
    "text": "1.2 Load Secondary Data\n\nCensus\nPurpose: Pull demographic and housing data at the block group level for Philadelphia from the 2023 5-year ACS. This data will provide predictors for neighborhood characteristics in our modeling.\nVariables Collected:\nMedian household income (B19013)\nPercentage of family households (B11001)\nEducation attainment: percent of population 25+ with a bachelor’s degree or higher (B15003)\nHousing vacancy rate (B25002)\nRacial composition: percent white (B02001)\n\nLoad Philly Census Data from Previously Retrieved Files\n\n# Relative to project root\nfolder_path &lt;- here(\"data\", \"Philly Census\")\n\ncsv_path &lt;- file.path(folder_path, \"philly_blockgroups_metrics.csv\")\nshp_path &lt;- file.path(folder_path, \"philly_blockgroups.shp\")\n\n# Csv with Block Group Geo IDs and metrics\nphilly_blockgroup &lt;- read_csv(csv_path, show_col_types = FALSE)\n\n# Shp File including geometry\nphilly_bg_sf &lt;- st_read(shp_path, quiet = TRUE)\n\n\n\nObserve Summary Statistics from target metrics.\n\nnumeric_vars &lt;- c(\"median_income\", \"pct_white\", \"pct_bachelors\", \"pct_vacant\")\nphilly_blockgroup %&gt;%\n  select(all_of(numeric_vars)) %&gt;%\n  summary()\n\n median_income      pct_white       pct_bachelors      pct_vacant     \n Min.   :  2499   Min.   :  0.000   Min.   :  0.00   Min.   :  0.000  \n 1st Qu.: 43598   1st Qu.:  5.352   1st Qu.: 12.65   1st Qu.:  1.206  \n Median : 63401   Median : 27.616   Median : 27.49   Median :  8.122  \n Mean   : 71011   Mean   : 35.758   Mean   : 34.14   Mean   :  9.997  \n 3rd Qu.: 92716   3rd Qu.: 63.196   3rd Qu.: 50.13   3rd Qu.: 15.103  \n Max.   :250001   Max.   :100.000   Max.   :100.00   Max.   :100.000  \n NA's   :318      NA's   :64        NA's   :64       NA's   :72       \n\n\nA quick check of the census variables reveals some missing values and lower than epected values in median income. We will note this information but retain the missing values for now to maintain the full pitcure of census blocks.\n\n\n\nCleaning Methodology (Census)\nMedian income: Selected only the estimate column and renamed it for clarity.\nHousehold composition: Pivoted ACS table to wide format, then calculated total households and family households.\nEducation: Pivoted to wide format, summed relevant categories to compute percent of population with a bachelor’s degree or higher.\nVacancy: Pivoted to wide format, calculated percent of homes vacant (vacant_units / total_units * 100).\nRacial composition: Pivoted to wide format, computed percent white.\nMerging: Combined all datasets by GEOID to create a single dataframe philly_blockgroup with all variables.\nGeometry: Pulled block group shapefiles with ACS geometry and merged with philly_blockgroup to create philly_bg_map.\n\n\nNeighborhood (Polygon)\n\n\nCity Centers (Amenities)\n\n\nEducation\n\n\nJoining data together"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Philadelphia Housing Price Prediction",
    "section": "",
    "text": "Project Overview:\n\nMembers: Jack Bader, Date: October 27, 2025"
  }
]