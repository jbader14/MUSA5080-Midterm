[
  {
    "objectID": "appendix/appendix.html",
    "href": "appendix/appendix.html",
    "title": "Technical Appendix",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.2\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'scales'\n\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\n\nLinking to GEOS 3.13.1, GDAL 3.11.0, PROJ 9.6.0; sf_use_s2() is TRUE\n\nTo enable caching of data, set `options(tigris_use_cache = TRUE)`\nin your R script or .Rprofile.\n\nhere() starts at C:/Users/jcahi/OneDrive/Desktop/MUSA 5080/Midterm/MUSA5080-Midterm"
  },
  {
    "objectID": "appendix/appendix.html#load-and-philadelphia-house-sales-data",
    "href": "appendix/appendix.html#load-and-philadelphia-house-sales-data",
    "title": "Technical Appendix",
    "section": "1.1 Load and Philadelphia house sales data",
    "text": "1.1 Load and Philadelphia house sales data\n\n# Load Philly Property Sales data\nphl_sales &lt;- read_csv(\"../data/raw/opa_properties_public.csv\", show_col_types = FALSE)\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\n\nFilter to residential properties, 2023-2024 sales\n\n# Check data types\n# glimpse(phl_sales)\n\nphl_sales_res_23_24 &lt;- phl_sales |&gt;\n  filter(\n    category_code == 1, # Residential\n    year(sale_date) %in% c(2023, 2024), # 2023-24 sales\n    !is.na(category_code) & !is.na(sale_date) # Handle nulls\n  )\n\n\n\nRemove obvious errors\n\nphl_sales_clean &lt;- phl_sales_res_23_24 |&gt;\n  filter(\n    # Some sale_price are unrealistically too low ($0, $1 etc.)\n    sale_price &gt;= 10000,\n    # Exclude homes with 0 bathrooms\n    number_of_bathrooms &gt; 0,\n    # Some areas are unrealistically low (0, 1, etc.)\n    total_area &gt; 1,\n    # Some 0's remain in total_liveable_area after first area filter\n    total_livable_area &gt; 0,\n    # Filter our unrealistic year built\n    year_built &gt;= 1750\n    ) \n\n\n\nHandle missing values\n\n# Check how many features have NA values\n# sum(is.na(phl_sales_clean$number_of_bedrooms))\n# sum(is.na(phl_sales_clean$number_of_bathrooms))\n# sum(is.na(phl_sales_clean$total_livable_area))\n# sum(is.na(phl_sales_clean$year_built))\n\n# Remove the 2 observations with NA values for number of bedrooms\nphl_sales_clean &lt;- phl_sales_clean |&gt;\n  filter(\n    !is.na(number_of_bedrooms)\n  )\n\n\n\nPreliminary Feature Engineering: Age = sale date - year built\n\nphl_sales_clean &lt;- phl_sales_clean |&gt;\n  mutate(\n    sale_year = year(sale_date),\n    age = sale_year - year_built\n  )\n\n\n\nDocument all cleaning decisions\n\nOur methodology for cleaning the Philadelphia home sales data is to focus on the features used in our model. As a group, we decided on the following independent variables to consider in our data exploration and model building to be: number of bathrooms, number of bedrooms, total livable area, and year built. We recognize that there is some risk of collinearity between these structural features, which will later be monitored and addressed if needed in the model building stage. Additionally, we also had to clean the sales price column since this is the variable we aim to predict in our model.\nFilter for only residential properties & sales made in 2023-24 (per instructions).\nFilter for realistic sales price &gt;= $10,000.\nFilter for houses with at least 1 bathroom. We will keep observations where number of bedrooms = 0 as this likely signifies a studio apartment. However, it is not feasible for homes to have zero bathrooms, so we will enforce a constraint that a home must have at least 1 bathroom to preserve data integrity.\nFilter for realistic total area &gt; 1 sq ft & realistic total livable area &gt; 0 sq ft.\nFilter for year built &gt;= 1750 (some homes were built in year 0).\nHandle missing values: We removed any missing values in our dependent variable of sales price, since it is crucial we have a true and accurate measure for prediction. We also checked which of our predictor variables had NA values after filtering. Only number of bedrooms had 2 remaining NA values. The rest had no NA values. To remedy this, we will remove the 2 observations from our data. Note, if there was substantial missing values in our predictors, we could use strategies such as imputing the NA values with the mean or median to use when building our model.\nPreliminary feature engineering: Rather than using year built in our Automated Valuation Model, it makes more sense to create a new variable age that is equal to the sale date minus the year built. The age variable is often easier to interpret in exploratory plots with the newer houses appearing on the left and older ones on the right. This is primarily a stylistic preference: the overall pattern of the data will remain the same but mirrored."
  },
  {
    "objectID": "appendix/appendix.html#load-secondary-data",
    "href": "appendix/appendix.html#load-secondary-data",
    "title": "Technical Appendix",
    "section": "1.2 Load Secondary Data",
    "text": "1.2 Load Secondary Data\n\nCensus\nPurpose: Pull demographic and housing data at the block group level for Philadelphia from the 2023 5-year ACS. This data will provide predictors for neighborhood characteristics in our modeling.\nVariables Collected:\nMedian household income (B19013)\nPercentage of family households (B11001)\nEducation attainment: percent of population 25+ with a bachelor’s degree or higher (B15003)\nHousing vacancy rate (B25002)\nRacial composition: percent white (B02001)\n\nLoad Philly Census Data from Previously Retrieved Files\n\n# Relative to project root\ncensus_path &lt;- here(\"data\", \"Philly Census\")\n\ncensus_csv_path &lt;- file.path(census_path, \"philly_blockgroups_metrics.csv\")\ncensus_shp_path &lt;- file.path(census_path, \"philly_blockgroups.shp\")\n\n# Csv with Block Group Geo IDs and metrics\nphilly_blockgroup &lt;- read_csv(census_csv_path, show_col_types = FALSE)\n\n# Shp File including geometry\nphilly_bg_sf &lt;- st_read(census_shp_path, quiet = TRUE)\n\n\n\nObserve Summary Statistics from target metrics.\n\nnumeric_vars &lt;- c(\"median_income\", \"pct_white\", \"pct_bachelors\", \"pct_vacant\")\nphilly_blockgroup %&gt;%\n  select(all_of(numeric_vars)) %&gt;%\n  summary()\n\n median_income      pct_white       pct_bachelors      pct_vacant     \n Min.   :  2499   Min.   :  0.000   Min.   :  0.00   Min.   :  0.000  \n 1st Qu.: 43598   1st Qu.:  5.352   1st Qu.: 12.65   1st Qu.:  1.206  \n Median : 63401   Median : 27.616   Median : 27.49   Median :  8.122  \n Mean   : 71011   Mean   : 35.758   Mean   : 34.14   Mean   :  9.997  \n 3rd Qu.: 92716   3rd Qu.: 63.196   3rd Qu.: 50.13   3rd Qu.: 15.103  \n Max.   :250001   Max.   :100.000   Max.   :100.00   Max.   :100.000  \n NA's   :318      NA's   :64        NA's   :64       NA's   :72       \n\n\nA quick check of the census variables reveals some missing values and lower than epected values in median income. We will note this information but retain the missing values for now to maintain the full pitcure of census blocks.\n\n\n\nCleaning Methodology (Census)\nMedian income: Selected only the estimate column and renamed it for clarity.\nHousehold composition: Pivoted ACS table to wide format, then calculated total households and family households.\nEducation: Pivoted to wide format, summed relevant categories to compute percent of population with a bachelor’s degree or higher.\nVacancy: Pivoted to wide format, calculated percent of homes vacant (vacant_units / total_units * 100).\nRacial composition: Pivoted to wide format, computed percent white.\nMerging: Combined all datasets by GEOID to create a single dataframe philly_blockgroup with all variables.\nGeometry: Pulled block group shapefiles with ACS geometry and merged with philly_blockgroup to create philly_bg_map.\n\n\nNeighborhood (Polygon)\nReading in Philadelphia Neighborhoods as a shp object. This will allow us to aggregate data on neighborhoods to identify catagorical metrics.\n\nneighborhood_folder &lt;- here(\"data\", \"philadelphia-neighborhoods\")\nneighborhood_path   &lt;- file.path(neighborhood_folder, \"philadelphia-neighborhoods.shp\")\n\n# Read the shapefile\nphilly_neighborhoods &lt;- st_read(neighborhood_path, quiet = TRUE)\n\nhead(philly_neighborhoods)\n\nSimple feature collection with 6 features and 5 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -75.23049 ymin: 39.98491 xmax: -75.0156 ymax: 40.11269\nGeodetic CRS:  WGS 84\n             NAME         LISTNAME         MAPNAME Shape_Leng Shape_Area\n1      BRIDESBURG       Bridesburg      Bridesburg   27814.55   44586264\n2       BUSTLETON        Bustleton       Bustleton   48868.46  114050424\n3      CEDARBROOK       Cedarbrook      Cedarbrook   20021.42   24871745\n4   CHESTNUT_HILL    Chestnut Hill   Chestnut Hill   56394.30   79664975\n5      EAST_FALLS       East Falls      East Falls   27400.78   40576888\n6 MOUNT_AIRY_EAST Mount Airy, East East Mount Airy   28845.55   43152470\n                        geometry\n1 POLYGON ((-75.06773 40.0054...\n2 POLYGON ((-75.0156 40.09487...\n3 POLYGON ((-75.18848 40.0727...\n4 POLYGON ((-75.21221 40.0860...\n5 POLYGON ((-75.18476 40.0282...\n6 POLYGON ((-75.18087 40.0432...\n\n\n\n\nCity Centers (Amenities)\n\n\nEducation\nWe used two datasets from OpenDataPhilly.com to identify schools geolocation and populated the metrics off Attendance percent and Withdrawal volumes from those schools.\n\n# Relative to project root\neducation_path &lt;- here(\"data\", \"Education\")\n\neducation_csv_path &lt;- file.path(education_path, \"philadelphia_schools.csv\")\neducation_shp_path &lt;- file.path(education_path, \"Schools Shape\", \"Schools.shp\")\n\n# Csv with School Names and metrics\nphilly_schools &lt;- read_csv(education_csv_path, show_col_types = FALSE)\n\n# Shp File including geometry\nphilly_schools_sf &lt;- st_read(education_shp_path, quiet = TRUE)\n\nWe joined the csv file containing the metrics with the shp file containing geoloaction.\n\n# Joining Schools csv metrics to shp file. Joined on 'location_i' (shp) and 'School_code (csv)\n# Keeping metrics for Attendance and Withdrawals\n\n# Select relevant metrics from CSV\nschool_metrics &lt;- philly_schools %&gt;%\n  select(School_code, Attendance, Withdrawals) %&gt;%\n  mutate(School_code = as.character(School_code))\n\nphilly_schools_sf &lt;- philly_schools_sf %&gt;%\n  left_join(school_metrics,\n            by = c(\"location_i\" = \"School_code\"))\n\n\nphilly_schools_sf_clean &lt;- philly_schools_sf %&gt;%\n  filter(!is.na(Attendance) & !is.na(Withdrawals))\n\n\nnames(philly_schools_sf_clean)\n\n [1] \"aun\"         \"school_num\"  \"location_i\"  \"school_nam\"  \"school_n_1\" \n [6] \"street_add\"  \"zip_code\"    \"phone_numb\"  \"grade_leve\"  \"grade_org\"  \n[11] \"enrollment\"  \"type\"        \"type_speci\"  \"objectid\"    \"Attendance\" \n[16] \"Withdrawals\" \"geometry\"   \n\nnrow(philly_schools_sf_clean)\n\n[1] 204\n\n\nOnce joined, we dropped rows that did not have values in Attendance and Withdrawal. This resulted in 204 public schools and their metrics located in Philadelphia City Limits.\n\n\nJoining data together"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Philadelphia Housing Price Prediction",
    "section": "",
    "text": "Project Overview:\n\nMembers: Jack Bader, Date: October 27, 2025"
  },
  {
    "objectID": "presentation/presentation.html#key-findings-and-recommendations",
    "href": "presentation/presentation.html#key-findings-and-recommendations",
    "title": "Predicting Housing Sales",
    "section": "Key Findings and Recommendations",
    "text": "Key Findings and Recommendations\n\nOur model had an average error of 48.31% and explains 64% of the variance of logged housing prices (need help explaining this).\nFindings\n\nRecommendations\n\n\nConsidering a tax scheme that subsidizes the upkeep and affordability of the middle-aged housing units"
  },
  {
    "objectID": "presentation/presentation.html#nuanced-neighborhoods",
    "href": "presentation/presentation.html#nuanced-neighborhoods",
    "title": "Predicting Housing Sales",
    "section": "Nuanced Neighborhoods",
    "text": "Nuanced Neighborhoods"
  },
  {
    "objectID": "presentation/presentation.html#equity-concerns",
    "href": "presentation/presentation.html#equity-concerns",
    "title": "Predicting Housing Sales",
    "section": "Equity Concerns",
    "text": "Equity Concerns"
  },
  {
    "objectID": "presentation/presentation.html#limitations",
    "href": "presentation/presentation.html#limitations",
    "title": "Predicting Housing Sales",
    "section": "Limitations",
    "text": "Limitations"
  },
  {
    "objectID": "presentation/presentation.html",
    "href": "presentation/presentation.html",
    "title": "Predicting Housing Sales",
    "section": "",
    "text": "Our model had an avereage error of 48.31% and explains 64% of the variance of logged housing prices (need help explaining this).\nFindings\n\n\nThe number of bathrooms is a better predictor than number of bedrooms\n\nBathrooms: β = 0.151, p &lt; 0.001\nBedrooms: β = 0.018, p &lt; 0.001\n\nLivable Area still King\n\nLog(Livable Area):β = 0.508, p &lt; 0.001\n\n\n\nRecommendations\n\n\nSubsidize affordable housing construction to bring prices down to level of older units\n\n\n\n\n\n\nSale by Age"
  },
  {
    "objectID": "presentation/presentation.html#most-impactful-features",
    "href": "presentation/presentation.html#most-impactful-features",
    "title": "Predicting Housing Sales",
    "section": "Most Impactful features",
    "text": "Most Impactful features"
  },
  {
    "objectID": "presentation/presentation.html#key-issues",
    "href": "presentation/presentation.html#key-issues",
    "title": "Predicting Housing Sales",
    "section": "Key Issues",
    "text": "Key Issues"
  },
  {
    "objectID": "presentation/presentation.html#data-sources",
    "href": "presentation/presentation.html#data-sources",
    "title": "Predicting Housing Sales",
    "section": "Data Sources",
    "text": "Data Sources\n\nCity of Philadelphia\nPhiladelphia Properties and Current Assessments\nOpenDataPhilly\n\nPhiladelphia Neighborhoods Polygon\nSchool attendance, withdrawls, location\n\nGeofrabrik\n\nEconomic activity locations\n\nUS Census:\n\n5-year ACS data\n\nEducation, vacancy, family share, percent white, median income"
  },
  {
    "objectID": "presentation/presentation.html#a-mapped-observations",
    "href": "presentation/presentation.html#a-mapped-observations",
    "title": "Predicting Housing Sales",
    "section": "A mapped observations",
    "text": "A mapped observations\n(i.e. where are expensive homes)\n\nMissing?"
  },
  {
    "objectID": "presentation/presentation.html#price-drivers",
    "href": "presentation/presentation.html#price-drivers",
    "title": "Predicting Housing Sales",
    "section": "Price Drivers",
    "text": "Price Drivers\n\nEconomic Density\nLivable Space\nBedrooms v Bathrooms\nBuilding Age"
  },
  {
    "objectID": "presentation/presentation.html#model-comparison",
    "href": "presentation/presentation.html#model-comparison",
    "title": "Predicting Housing Sales",
    "section": "Model Comparison",
    "text": "Model Comparison"
  },
  {
    "objectID": "presentation/presentation.html#hardest-neighborhoods-to-predict",
    "href": "presentation/presentation.html#hardest-neighborhoods-to-predict",
    "title": "Predicting Housing Sales",
    "section": "Hardest Neighborhoods to Predict",
    "text": "Hardest Neighborhoods to Predict"
  },
  {
    "objectID": "presentation/presentation.html#recommendations",
    "href": "presentation/presentation.html#recommendations",
    "title": "Predicting Housing Sales",
    "section": "Recommendations",
    "text": "Recommendations"
  },
  {
    "objectID": "presentation/presentation.html#limitations-next-steps",
    "href": "presentation/presentation.html#limitations-next-steps",
    "title": "Predicting Housing Sales",
    "section": "Limitations & Next Steps",
    "text": "Limitations & Next Steps"
  },
  {
    "objectID": "presentation/presentation.html#questions",
    "href": "presentation/presentation.html#questions",
    "title": "Predicting Housing Sales",
    "section": "Questions?",
    "text": "Questions?\n\nThank you!\n\n\nContact Information:\n\nJack Bader\n\njbader14@upenn.edu\n\nMatthew Levy\n\nmblevy@upenn.edu\n\nTim Wen\n\nsw6as@upenn.edu\n\n\n\n\nJoey Cahill\n\ncahill1@upenn.edu\n\nSam Sen\n\nsen1@upenn.edu\n\nYe Zhang\n\nyezhang1@upenn.edu"
  }
]